version: '3'

services:
  # [source_postgres] is a PostgreSQL database that will act as the source database for the ETL process.
  source_postgres:
    image: postgres:latest
    container_name: source_postgres
    ports: 
      - '5433:5432'
    networks:
      - elt_network
    environment:
      - POSTGRES_DB=source_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres

    volumes:
      - ./source_db_init/init.sql:/docker-entrypoint-initdb.d/init.sql
      - source_db_data:/var/lib/postgresql/data

# [destination_postgres] is a PostgreSQL database that will act as the destination database for the ETL process.
  destination_postgres: 
    image: postgres:latest
    container_name: destination_postgres
    ports: 
      - '5434:5432'
    networks:
      - elt_network
    environment:
      - POSTGRES_DB=destination_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    # volumes:
    #   - destination_db_data:/var/lib/postgresql/data
    

# [airflow-postgres] is a PostgreSQL database that will be used by Apache Airflow to store metadata and task execution logs.
  airflow-postgres:
    image: postgres:latest
    container_name: airflow-postgres
    networks:
      - elt_network
    environment:
      - POSTGRES_DB=airflow
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
    volumes:
      - airflow-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

# [airflow-init] is a container that initializes the Apache Airflow database by running the airflow db init and airflow users create commands.
  airflow-init:
    image: apache/airflow:latest
    container_name: airflow-init
    depends_on:
      - airflow-postgres
    networks:
      - elt_network
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres:5432/airflow
    command: >
      bash -c "airflow db migrate && airflow users create -u airflow -p airflow -f Abdullah -l Abaza -r Admin -e abdullahabaza96@gmail.com"
  
# [airflow-webserver] is the Apache Airflow webserver that provides a UI for managing and monitoring workflows.
  airflow-webserver:
    build:
      context: .
      dockerfile: DockerFile
    container_name: airflow-webserver
    depends_on:
      - airflow-init
    networks:
      - elt_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./elt_script:/opt/airflow/elt_script
      - ./dbt_project:/opt/dbt
      - ~/.dbt:/root/.dbt
      - /var/run/docker.sock:/var/run/docker.sock
    env_file:
      - .env
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW_CONN_DESTINATION_DB=postgresql+psycopg2://postgres:postgres@destination_postgres:5434/destination_db
      - AIRFLOW__WEBSERVER__DEFAULT_USER_USERNAME=airflow
      - AIRFLOW__WEBSERVER__DEFAULT_USER_PASSWORD=airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - AIRFLOW_WWW_USER_USERNAME=airflow
      - AIRFLOW_WWW_USER_PASSWORD=airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}

    ports:
      - 8080:8080
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health || exit 1"]
      interval: 30s
      retries: 5
      start_period: 10s

# [airflow-scheduler] is the Apache Airflow scheduler that schedules and executes workflows.
  airflow-scheduler:
    build:
      context: .
      dockerfile: DockerFile
    container_name: airflow-scheduler
    depends_on:
      - airflow-init
    networks:
      - elt_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./elt_script:/opt/airflow/elt_script
      - ./dbt_project:/opt/dbt
      - ~/.dbt:/root/.dbt
      - /var/run/docker.sock:/var/run/docker.sock
    env_file:
      - .env
    environment:
      - LOAD_EX=n
      - EXCUTOR=Local
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW_CONN_DESTINATION_DB=postgresql+psycopg2://postgres:postgres@destination_postgres:5434/destination_db
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - AIRFLOW_WWW_USER_USERNAME=airflow
      - AIRFLOW_WWW_USER_PASSWORD=airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}

    command: scheduler




networks:
  elt_network:
    driver: bridge
volumes: 
  source_db_data: {}
  # destination_db_data: {}
  airflow-db-volume: {}



  